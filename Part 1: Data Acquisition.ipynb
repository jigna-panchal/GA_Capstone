{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Predicting Character based on Dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goals: \n",
    "1) Scrape data from the web for all transcripts\n",
    "\n",
    "2) Focus on the models - use NLP and GridSearchCV to obtain the best model with the best parameters\n",
    "\n",
    "3) Be able to accurately predict who would be likely to say a line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friends Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import regex\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain a source for the data\n",
    "A quick google search led me to the following website where all of the episodes have been transcribed:\n",
    "http://livesinabox.com/friends\n",
    "\n",
    "Each episode was transcribed on a separate web page. Therefore, I started the process by reviewing the html structure of one page. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with one page and understand HTML text\n",
    "Use Beautiful Soup to find all p tags in html scripts\n",
    "\n",
    "Note - most episodes followed the same html patterns. However, there were some irregular episodes for which reviewing those one by one helped me group them together and know how to modify my code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ('http://livesinabox.com/friends/season2/212toasb.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(rescrape_urls[5])\n",
    "soup = BeautifulSoup(r.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test by obtaining the characters and lines from one episode and use RegEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "lines = []\n",
    "for p in ps:\n",
    "    char = regex.findall(r\"[A-Z][a-zA-Z. ]+:\",p.text)\n",
    "    if char != []:\n",
    "        if char[0] != \"Scene:\":\n",
    "            characters.append(char[0])\n",
    "            index = regex.search(char[0], p.text).start() + len(char[0])\n",
    "            line = p.text[index:]\n",
    "            lines.append(line.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 301\n"
     ]
    }
   ],
   "source": [
    "#Length of the characters equals the length of the lines! \n",
    "print(len(characters), len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that it works on one, continue with the rest\n",
    "Obtain the urls for each transcript page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links_url = 'http://livesinabox.com/friends/scripts.shtml'\n",
    "r = requests.get(all_links_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pattern = regex.compile(r'<li><a href=\"(season\\d+/\\d+\\w+.htm)')\n",
    "all_episodes = regex.findall(url_pattern, r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_episodes_urls = ['http://livesinabox.com/friends/'+episode for episode in all_episodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following were episodes split into two parts but only have one transcript. Therefore, need to remove the link to the second transcript to avoid duplication. \n",
    "Season 4 - ep 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_episodes_urls.remove('http://livesinabox.com/friends/season4/423uncut.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s02_irregular_urls = all_episodes_urls[35:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s02_irregular_urls.append(all_episodes_urls[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in s02_irregular_urls:\n",
    "    all_episodes_urls.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_episodes_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a for loop, obtain the characters, lines, title of episode, season #, and episode # for each transcript through season 8\n",
    "Seasons 1-8 are formatted similarly. There are differences in seasons 9 and 10. In addition, there are some irregularly formatted episodes, which will need to be scraped using their specific tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [01:06<00:00,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "Characters = []\n",
    "Lines = []\n",
    "Title = []\n",
    "Season = []\n",
    "Episode = []\n",
    "for url in tqdm(all_episodes_urls):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    ps = soup.find_all('p')\n",
    "    for p in ps:\n",
    "        char = regex.findall(r\"[A-Z][a-zA-Z. ]+:\",p.text)\n",
    "        if char != []:\n",
    "            if char[0] != \"Scene:\":\n",
    "                Characters.append(char[0])\n",
    "                index = regex.search(char[0], p.text).start() + len(char[0])\n",
    "                line = p.text[index:]\n",
    "                Lines.append(line.replace(\"\\n\",\" \"))\n",
    "                Title.append(soup.title.string)\n",
    "                season = regex.findall('friends/(\\w+\\d+)', url)\n",
    "                Season.append(season)\n",
    "                ep = regex.findall('friends/\\w+\\d+/(\\d+)', url)\n",
    "                Episode.append(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45817, 45817, 45817, 45817, 45817)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the len of the lists to ensure they are all the same length\n",
    "len(Characters), len(Lines), len(Title), len(Season), len(Episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the same procedure for Season 9 episodes\n",
    "Note - episodes 7, 11, and 15 are irregular therefore not included in the following scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to reformat url pattern for season 9\n",
    "all_links_url = 'http://livesinabox.com/friends/scripts.shtml'\n",
    "r = requests.get(all_links_url)\n",
    "url_pattern = regex.compile(r'<a href=\"(season9/\\d+\\w*.\\w+)\">')\n",
    "s09_episodes = regex.findall(url_pattern, r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s09_episodes_urls = ['http://livesinabox.com/friends/'+episode for episode in s09_episodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://livesinabox.com/friends/season9/915mug.htm'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove episodes 7, 11, 15 from list due to irregularities\n",
    "s09_episodes_urls.pop(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://livesinabox.com/friends/season9/911work.htm'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove episodes 7, 11, 15 from list due to irregularities\n",
    "s09_episodes_urls.pop(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://livesinabox.com/friends/season9/907song.htm'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove episodes 7, 11, 15 from list due to irregularities\n",
    "s09_episodes_urls.pop(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note - episode 23 and 24 not included because they are in a different format.... will need to manually scrape and add them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:09<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "#Need to reformat for season 9 patterns.... ie the title\n",
    "for url in tqdm(s09_episodes_urls):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    ps = soup.find_all('p')\n",
    "    for p in ps:\n",
    "        char = regex.findall(r\"[A-Z][a-zA-Z. ]+:\",p.text)\n",
    "        if char != []:\n",
    "            if char[0] != \"Scene:\":\n",
    "                Characters.append(char[0])\n",
    "                index = regex.search(char[0], p.text).start() + len(char[0])\n",
    "                line = p.text[index:]\n",
    "                Lines.append(line.replace(\"\\n\",\" \"))\n",
    "                season = regex.findall('friends/(\\w+\\d+)', url)\n",
    "                Season.append(season)\n",
    "                ep = regex.findall('friends/season9/(\\d+)', url)\n",
    "                Episode.append(ep)\n",
    "                try:\n",
    "                    Title.append(soup.title.string)\n",
    "                except:\n",
    "                    Title.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50777, 50777, 50777, 50777, 50777)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Characters), len(Lines), len(Title), len(Season), len(Episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Season 2 (9, 12:23) and  9 (7,11,15, 23/24) Irregular Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s09_ep2324_url = 'http://livesinabox.com/friends/season9/0923-0924.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s09_irregular_urls = ['http://livesinabox.com/friends/season9/907song.htm',\n",
    "                      'http://livesinabox.com/friends/season9/911work.htm',\n",
    "                      'http://livesinabox.com/friends/season9/915mug.htm',\n",
    "                     'http://livesinabox.com/friends/season9/0923-0924.html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "irregular_urls = s09_irregular_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(irregular_urls):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    ps = soup.find('body').text\n",
    "    for p in ps.split(\"\\n\"):\n",
    "        char = regex.findall(r\"[A-Z][a-zA-Z. ]+:\",p)\n",
    "        if char != []:\n",
    "            if char[0] not in (\"Scene:\",'Teleplay by:','Story by:','Directed by:'):\n",
    "                Characters.append(char[0])\n",
    "                index = regex.search(char[0], p).start() + len(char[0])\n",
    "                line = p[index:]\n",
    "                Lines.append(line.replace(\"<br>\",\"\",))\n",
    "                season = regex.findall('friends/(\\w+\\d+)', url)\n",
    "                Season.append(season)\n",
    "                ep = regex.findall('friends/season\\d/(\\d+)', url)\n",
    "                Episode.append(ep)\n",
    "                try:\n",
    "                    Title.append(soup.title.string)\n",
    "                except:\n",
    "                    Title.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52108, 52108, 52108, 52108, 52108)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Characters), len(Lines), len(Title), len(Season), len(Episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://livesinabox.com/friends/season2/212toasb.htm',\n",
       " 'http://livesinabox.com/friends/season2/214towpv.htm',\n",
       " 'http://livesinabox.com/friends/season2/215rryk.htm',\n",
       " 'http://livesinabox.com/friends/season2/216jmo.htm',\n",
       " 'http://livesinabox.com/friends/season2/217emi.htm',\n",
       " 'http://livesinabox.com/friends/season2/218drd.htm',\n",
       " 'http://livesinabox.com/friends/season2/219ewg.htm',\n",
       " 'http://livesinabox.com/friends/season2/220oyd.htm',\n",
       " 'http://livesinabox.com/friends/season2/221towtb.htm',\n",
       " 'http://livesinabox.com/friends/season2/222towtp.htm',\n",
       " 'http://livesinabox.com/friends/season2/223towcp.htm',\n",
       " 'http://livesinabox.com/friends/season2/209towpd.htm']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s02_irregular_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:04<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(s02_irregular_urls):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    ps = soup.prettify()\n",
    "    for p in ps.split(\"<br/>\"):\n",
    "        char = regex.findall(r\"[A-Z][a-zA-Z. ]+:\",p)\n",
    "        if char != []:\n",
    "            if char[0] not in (\"Scene:\",'Teleplay by:','Story by:','Directed by:','Written by:','Transcribed by:',):\n",
    "                Characters.append(char[0])\n",
    "                index = regex.search(char[0], p).start() + len(char[0])\n",
    "                line = p[index:]\n",
    "                Lines.append(line.lstrip('\\n  </b>\\n  ').replace(\"</br>\",\"\",).replace(\"\\n\",\"\").replace(\"  \",\" \").strip())\n",
    "                season = regex.findall('friends/(\\w+\\d+)', url)\n",
    "                Season.append(season)\n",
    "                ep = regex.findall('friends/\\w+\\d+/(\\d+)', url)\n",
    "                Episode.append(ep)\n",
    "                try:\n",
    "                    Title.append(soup.title.string)\n",
    "                except:\n",
    "                    Title.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55384, 55384, 55384, 55384, 55384)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Characters), len(Lines), len(Title), len(Season), len(Episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the same procedure for Season 10 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links_url = 'http://livesinabox.com/friends/scripts.shtml'\n",
    "r = requests.get(all_links_url)\n",
    "url_pattern = regex.compile(r'<a href=\"(\\d+.shtml)')\n",
    "s10_episodes = regex.findall(url_pattern, r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "s10_episodes_urls = ['http://livesinabox.com/friends/'+episode for episode in s10_episodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crazy For Friends - 1001 - The One After Joey And Rachel Kiss'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('http://livesinabox.com/friends/1001.shtml')\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:10<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(s10_episodes_urls):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    ps = soup.find_all('p')\n",
    "    for p in ps:\n",
    "        char = regex.findall(r\"[A-Z][a-zA-Z. ]+:\",p.text)\n",
    "        if char != []:\n",
    "            if char[0] != \"Scene:\":\n",
    "                Characters.append(char[0])\n",
    "                index = regex.search(char[0], p.text).start() + len(char[0])\n",
    "                line = p.text[index:]\n",
    "                Lines.append(line.replace(\"\\n\",\" \"))\n",
    "                season = regex.findall('friends/(\\d\\d)', url)\n",
    "                Season.append(season)\n",
    "                ep = regex.findall('friends/(\\d+)', url)\n",
    "                Episode.append(ep)\n",
    "                try:\n",
    "                    Title.append(soup.title.string)\n",
    "                except:\n",
    "                    Title.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61116, 61116, 61116, 61116, 61116)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Characters), len(Lines), len(Title), len(Season), len(Episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean the lists as needed\n",
    "The Season and Episode lists are a list of lists, therefore, wanted to make it into just one list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['season1'], ['season1'], ['season1']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Season[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode = [value[0] for value in Episode]\n",
    "Season = [value[0] for value in Season]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2383"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Title.count('Untitled Document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug all of the lists into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Season']=Season\n",
    "df['Episode'] = Episode\n",
    "df['Title'] = Title\n",
    "df['Character'] = Characters\n",
    "df['Line'] = Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the data frame \n",
    "review various episodes to ensure we obtained the data we wanted and in the format we wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Title</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15850</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Chandler:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15851</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Joey:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15852</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Mrs. Burkart:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15853</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Phoebe:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15854</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Monica:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Phoebe:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Mrs. Burkart:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15857</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Phoebe:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15858</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Mrs. Burkart:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15859</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Phoebe:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15860</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Mrs. Burkart:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15861</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Phoebe:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15862</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Monica:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15863</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Cheryl:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Ross:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Cheryl:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15866</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Cheryl:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15867</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Ross:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15868</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Cheryl:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15869</th>\n",
       "      <td>season4</td>\n",
       "      <td>406</td>\n",
       "      <td>The One With The Dirty Girl</td>\n",
       "      <td>Ross:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Season Episode                        Title      Character Line\n",
       "15850  season4     406  The One With The Dirty Girl      Chandler:     \n",
       "15851  season4     406  The One With The Dirty Girl          Joey:     \n",
       "15852  season4     406  The One With The Dirty Girl  Mrs. Burkart:     \n",
       "15853  season4     406  The One With The Dirty Girl        Phoebe:     \n",
       "15854  season4     406  The One With The Dirty Girl        Monica:     \n",
       "15855  season4     406  The One With The Dirty Girl        Phoebe:     \n",
       "15856  season4     406  The One With The Dirty Girl  Mrs. Burkart:     \n",
       "15857  season4     406  The One With The Dirty Girl        Phoebe:     \n",
       "15858  season4     406  The One With The Dirty Girl  Mrs. Burkart:     \n",
       "15859  season4     406  The One With The Dirty Girl        Phoebe:     \n",
       "15860  season4     406  The One With The Dirty Girl  Mrs. Burkart:     \n",
       "15861  season4     406  The One With The Dirty Girl        Phoebe:     \n",
       "15862  season4     406  The One With The Dirty Girl        Monica:     \n",
       "15863  season4     406  The One With The Dirty Girl        Cheryl:     \n",
       "15864  season4     406  The One With The Dirty Girl          Ross:     \n",
       "15865  season4     406  The One With The Dirty Girl        Cheryl:     \n",
       "15866  season4     406  The One With The Dirty Girl        Cheryl:     \n",
       "15867  season4     406  The One With The Dirty Girl          Ross:     \n",
       "15868  season4     406  The One With The Dirty Girl        Cheryl:     \n",
       "15869  season4     406  The One With The Dirty Girl          Ross:     "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[15850:15870]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze the data frame using different aggregations\n",
    "1. Count the number of lines per episode to see how consistent it is and whether there were any episodes that had missing lines\n",
    "1. Count the number of blank lines by episode\n",
    "\n",
    "This helps us understand where we might have to rescrape certain episodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10',\n",
       " 'season1',\n",
       " 'season2',\n",
       " 'season3',\n",
       " 'season4',\n",
       " 'season5',\n",
       " 'season6',\n",
       " 'season7',\n",
       " 'season8',\n",
       " 'season9'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.Season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = [len(set(df[df.Season == season]['Episode'])) for season in set(df.Season)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(total_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Title</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Season  Title  Character  Line\n",
       "Episode                                \n",
       "116           2      2          2     2\n",
       "224           2      2          2     2\n",
       "913          56     56         56    56\n",
       "114         180    180        180   180\n",
       "712         198    198        198   198"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Episode']).count().sort_values(by='Line')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_lines = df[df.Line == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Title</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Season  Title  Character  Line\n",
       "Episode                                \n",
       "302         282    282        282   282\n",
       "608         251    251        251   251\n",
       "406         243    243        243   243\n",
       "819          79     79         79    79\n",
       "913          55     55         55    55\n",
       "813          26     26         26    26\n",
       "717          12     12         12    12\n",
       "516          11     11         11    11\n",
       "707           9      9          9     9\n",
       "618           8      8          8     8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank_lines.groupby('Episode').count().sort_values(by='Line', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the aggregation analysis performed above, it would seem that we need to rescrape Episodes 116, 224, 913, 302, 608, and 406 as those were the episodes with either the least amount of scraped lines or the highest amount of blank lines. \n",
    "\n",
    "However, the total rescrape episodes (6) is immaterial to the total episodes (227 total, which is about 3%), therefore we will choose not to rescrape the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframe to a CSV\n",
    "Once the data has been gathered, save to a CSV for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('friends_transcripts_s1_10.csv', columns=['Season', 'Episode', 'Title', 'Character', 'Line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
